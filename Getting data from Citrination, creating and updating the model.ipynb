{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from Citrination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from citrination_client import CitrinationClient\n",
    "from citrination_client import PifQuery\n",
    "from pypif.pif import dumps\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import yaml\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#client = CitrinationClient(site='my_site',api_key='my_key' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_datasets = [1,15,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['q_Imax', 'Imax_over_Imean', 'Imax_sharpness','logI_fluctuation', 'logI_max_over_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return dataframe with features and labels \n",
    "def get_data_from_Citrination(client, dataset_id_list):\n",
    "    df = pd.DataFrame(columns= [[ 'q_Imax', 'Imax_over_Imean', 'Imax_sharpness','logI_fluctuation', 'logI_max_over_std', 'bad_data', 'form', 'precursor', 'structure']])\n",
    "    for dataset in dataset_id_list:\n",
    "        query_dataset = PifQuery(include_datasets=[dataset])\n",
    "        query_result = client.search(query_dataset)\n",
    "        pifs = [x.system for x in query_result.hits]\n",
    "        for line in pifs: # every line of pifs is one sample; we need to extract labels and features from it\n",
    "            try:\n",
    "                my_str = dumps(line)\n",
    "                obj = json.loads(my_str) # to transform the string to dictionary\n",
    "                \n",
    "                # default values for labels\n",
    "                bad_data = False\n",
    "                form = False\n",
    "                precursor = False\n",
    "                structure = False\n",
    "                    \n",
    "                for pr in obj['properties']:\n",
    "\n",
    "                    # extract features                    \n",
    "                    if pr['name'] == 'q_Imax':\n",
    "                        q_Imax = np.float32(pr['scalars'][0]['value'])\n",
    "                    if pr['name'] == 'Imax_over_Imean':\n",
    "                        Imax_over_Imean = np.float32(pr['scalars'][0]['value'])\n",
    "                    if pr['name'] == 'Imax_sharpness':\n",
    "                        Imax_sharpness = np.float32(pr['scalars'][0]['value'])\n",
    "                    if pr['name'] == 'logI_fluctuation':\n",
    "                        logI_fluctuation = np.float32(pr['scalars'][0]['value'])\n",
    "                    if pr['name'] == 'logI_max_over_std':\n",
    "                        logI_max_over_std = np.float32(pr['scalars'][0]['value'])\n",
    "\n",
    "                    # extract labels\n",
    "                    if pr['name'] == 'bad_data':\n",
    "                        bad_data = True\n",
    "                        continue\n",
    "                    if pr['name'] == 'form_factor_scattering':\n",
    "                        form = True\n",
    "                    if pr['name'] == 'diffraction_peaks':\n",
    "                        structure = True\n",
    "                    if pr['name'] == 'precursor scattering':\n",
    "                        precursor = True\n",
    "\n",
    "                df.loc[df.shape[0]] = [q_Imax, Imax_over_Imean, Imax_sharpness, logI_fluctuation, \n",
    "                                           logI_max_over_std, bad_data, form, precursor, structure]\n",
    "            except:\n",
    "                # May be in PAWS we need to put a custom exeption here\n",
    "                my_str = dumps(line)\n",
    "                obj = json.loads(my_str) # to transform the string to dictionary\n",
    "                print(obj)\n",
    "                continue\n",
    "                                 \n",
    "    return df.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = get_data_from_Citrination(client, list_of_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_Imax</th>\n",
       "      <th>Imax_over_Imean</th>\n",
       "      <th>Imax_sharpness</th>\n",
       "      <th>logI_fluctuation</th>\n",
       "      <th>logI_max_over_std</th>\n",
       "      <th>bad_data</th>\n",
       "      <th>form</th>\n",
       "      <th>precursor</th>\n",
       "      <th>structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488538</td>\n",
       "      <td>1.312717</td>\n",
       "      <td>1.271242</td>\n",
       "      <td>7.916098</td>\n",
       "      <td>6.268310</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.275225</td>\n",
       "      <td>1.234932</td>\n",
       "      <td>1.132456</td>\n",
       "      <td>9.904497</td>\n",
       "      <td>5.549794</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357429</td>\n",
       "      <td>1.275898</td>\n",
       "      <td>1.166689</td>\n",
       "      <td>5.827428</td>\n",
       "      <td>3.660412</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336618</td>\n",
       "      <td>1.240092</td>\n",
       "      <td>1.143083</td>\n",
       "      <td>7.461594</td>\n",
       "      <td>4.006636</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227360</td>\n",
       "      <td>1.254006</td>\n",
       "      <td>1.229550</td>\n",
       "      <td>6.997641</td>\n",
       "      <td>5.272323</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     q_Imax  Imax_over_Imean  Imax_sharpness  logI_fluctuation  \\\n",
       "0  0.488538         1.312717        1.271242          7.916098   \n",
       "1  0.275225         1.234932        1.132456          9.904497   \n",
       "2  0.357429         1.275898        1.166689          5.827428   \n",
       "3  0.336618         1.240092        1.143083          7.461594   \n",
       "4  0.227360         1.254006        1.229550          6.997641   \n",
       "\n",
       "   logI_max_over_std  bad_data   form  precursor  structure  \n",
       "0           6.268310      True  False      False      False  \n",
       "1           5.549794      True  False      False      False  \n",
       "2           3.660412      True  False      False      False  \n",
       "3           4.006636      True  False      False      False  \n",
       "4           5.272323      True  False      False      False  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1750, 9)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_rows = np.random.permutation(d.index)\n",
    "data = d.loc[shuffled_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 19, 0]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to save the version of sklearn to use in PAWS\n",
    "current_version = list(map(int,sklearn.__version__.split('.')))\n",
    "major,minor,patch = current_version\n",
    "current_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am saving version of sklearn with all scalers and models. \n",
    "# Then I will dump them into a yaml file that will be used in PAWS app.\n",
    "scalers = {} \n",
    "models = {}\n",
    "scalers_and_models = {'version':current_version, 'scalers' : scalers, 'models': models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad Data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to train the model on all avalible data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data[features])\n",
    "log = linear_model.SGDClassifier(alpha= 0.001,loss= 'log', l1_ratio= 0.95, penalty= 'elasticnet')\n",
    "log.fit(scaler.transform(data[features]), data['bad_data'])\n",
    "\n",
    "# save the scaler and model\n",
    "scalers['bad_data'] = scaler.__dict__\n",
    "models['bad_data'] = log.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad data score:  0.982857142857\n"
     ]
    }
   ],
   "source": [
    "score = log.score(scaler.transform(data[features]), data['bad_data']) # here I test on the same data just to be sure the model works\n",
    "print(\"bad data score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we need only \"good\" data\n",
    "data_good = data[data['bad_data']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bad_data_model = log\n",
    "bad_data_scaler = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form Scattering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to train the model on all avalible data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data_good[features])\n",
    "log = linear_model.SGDClassifier(alpha= 0.001,loss= 'log', penalty= 'none')\n",
    "log.fit(scaler.transform(data_good[features]), data_good['form'])\n",
    "\n",
    "# save the scaler and model\n",
    "scalers['form_factor_scattering'] = scaler.__dict__\n",
    "models['form_factor_scattering'] = log.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "form score:  0.987428571429\n"
     ]
    }
   ],
   "source": [
    "score = log.score(scaler.transform(data[features]), data['form']) # here I test on the same data just to be sure the model works\n",
    "print(\"form score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "form_model = log\n",
    "form_scaler = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precursor Scattering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to train the model on all avalible data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data_good[features])\n",
    "log = linear_model.SGDClassifier(alpha= 0.01,loss= 'log', l1_ratio= 0.95, penalty= 'l1')\n",
    "log.fit(scaler.transform(data_good[features]), data_good['precursor'])\n",
    "\n",
    "# save the scaler and model\n",
    "scalers['precursor_scattering'] = scaler.__dict__\n",
    "models['precursor_scattering'] = log.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precursor score:  0.756571428571\n"
     ]
    }
   ],
   "source": [
    "score = log.score(scaler.transform(data[features]), data['precursor']) # here I test on the same data just to be sure the model works\n",
    "print(\"precursor score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precursor_model = log\n",
    "precursor_scaler = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffraction Peaks model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to train the model on all avalible data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data_good[features])\n",
    "log = linear_model.SGDClassifier(alpha= 0.001,loss= 'log', penalty= 'l1')\n",
    "log.fit(scaler.transform(data_good[features]), data_good['structure'])\n",
    "\n",
    "# save the scaler and model\n",
    "scalers['diffraction_peaks'] = scaler.__dict__\n",
    "models['diffraction_peaks'] = log.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structure score:  0.950857142857\n"
     ]
    }
   ],
   "source": [
    "score = log.score(scaler.transform(data[features]), data['structure']) # here I test on the same data just to be sure the model works\n",
    "print(\"structure score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structure_model = log\n",
    "structure_scaler = scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('scalers_and_models.yml', 'w') as yaml_file:\n",
    "    yaml.dump(scalers_and_models, yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('scalers_and_models.yml') as info:\n",
    "      s_and_m = yaml.load(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': {'bad_data': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[  1.80233753, -11.99343183,   5.52984411,   1.04371033,\n",
       "            -0.14865201]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([-12.72081737]),\n",
       "   'l1_ratio': 0.95,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a14835f78>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 5,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'elasticnet',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8751.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'diffraction_peaks': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[ -7.93713426,   9.07958068,  17.26923058,   0.        ,\n",
       "            -0.76772476]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([ 6.10308703]),\n",
       "   'l1_ratio': 0.15,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a379da0d8>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 5,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'l1',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8006.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'form_factor_scattering': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[ -1.26499006,  23.05349935,  -3.66371986,   0.2263169 ,\n",
       "            -1.64826423]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([ 16.27968844]),\n",
       "   'l1_ratio': 0.15,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a379da348>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 5,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'none',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8006.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'precursor_scattering': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.01,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[ 0.        , -2.45774815,  1.41993992, -0.10879928,  0.86784895]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([-0.63109835]),\n",
       "   'l1_ratio': 0.95,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a379da408>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 5,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'l1',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8006.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False}},\n",
       " 'scalers': {'bad_data': {'copy': True,\n",
       "   'mean_': array([  0.08458954,  20.3550401 ,   1.47136581,   5.36497042,   3.28268276]),\n",
       "   'n_samples_seen_': 1750,\n",
       "   'scale_': array([  0.10980206,  19.56918947,   0.70150315,   3.13884604,   1.16960072]),\n",
       "   'var_': array([  1.20564923e-02,   3.82953177e+02,   4.92106665e-01,\n",
       "            9.85235446e+00,   1.36796585e+00]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'diffraction_peaks': {'copy': True,\n",
       "   'mean_': array([  0.06239179,  22.08638401,   1.47110058,   4.98886844,   3.31720565]),\n",
       "   'n_samples_seen_': 1601,\n",
       "   'scale_': array([  0.04512096,  19.57581255,   0.69030832,   2.15678619,   0.98034173]),\n",
       "   'var_': array([  2.03590064e-03,   3.83212437e+02,   4.76525573e-01,\n",
       "            4.65172667e+00,   9.61069902e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'form_factor_scattering': {'copy': True,\n",
       "   'mean_': array([  0.06239179,  22.08638401,   1.47110058,   4.98886844,   3.31720565]),\n",
       "   'n_samples_seen_': 1601,\n",
       "   'scale_': array([  0.04512096,  19.57581255,   0.69030832,   2.15678619,   0.98034173]),\n",
       "   'var_': array([  2.03590064e-03,   3.83212437e+02,   4.76525573e-01,\n",
       "            4.65172667e+00,   9.61069902e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'precursor_scattering': {'copy': True,\n",
       "   'mean_': array([  0.06239179,  22.08638401,   1.47110058,   4.98886844,   3.31720565]),\n",
       "   'n_samples_seen_': 1601,\n",
       "   'scale_': array([  0.04512096,  19.57581255,   0.69030832,   2.15678619,   0.98034173]),\n",
       "   'var_': array([  2.03590064e-03,   3.83212437e+02,   4.76525573e-01,\n",
       "            4.65172667e+00,   9.61069902e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True}},\n",
       " 'version': [0, 19, 0]}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_and_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Updating the scalers and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_datasets_with_new_data = [16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_data = get_data_from_Citrination(client, list_of_datasets_with_new_data)\n",
    "shuffled_rows = np.random.permutation(new_data.index)\n",
    "new_data = new_data.loc[shuffled_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997885835095\n"
     ]
    }
   ],
   "source": [
    "#in paws we can use SaxsClassifier to recreate the old models and scalers and then we can update them using code below\n",
    "\n",
    "# bad data\n",
    "# updated the scaler:\n",
    "bad_data_scaler.partial_fit(new_data[features])\n",
    "# update the model\n",
    "bad_data_model.partial_fit(bad_data_scaler.transform(new_data[features]), new_data['bad_data'], classes=[True, False])\n",
    "\n",
    "scores = bad_data_model.score(bad_data_scaler.transform(new_data[features]), new_data['bad_data'])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for form, precursor, structure labels we will use only data with bad_data = False\n",
    "new_data_good = new_data[new_data['bad_data']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985138004246\n"
     ]
    }
   ],
   "source": [
    "# form factor scattering\n",
    "# updated the scaler:\n",
    "form_scaler.partial_fit(new_data_good[features])\n",
    "# update the model\n",
    "form_model.partial_fit(form_scaler.transform(new_data_good[features]), new_data_good['form'], classes=[True, False])\n",
    "\n",
    "scores = form_model.score(form_scaler.transform(new_data_good[features]), new_data_good['form'])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71974522293\n"
     ]
    }
   ],
   "source": [
    "# precursor scattering\n",
    "# updated the scaler:\n",
    "precursor_scaler.partial_fit(new_data_good[features])\n",
    "# update the model\n",
    "precursor_model.partial_fit(precursor_scaler.transform(new_data_good[features]), new_data_good['precursor'], classes=[True, False])\n",
    "\n",
    "scores = precursor_model.score(precursor_scaler.transform(new_data_good[features]), new_data_good['precursor'])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993630573248\n"
     ]
    }
   ],
   "source": [
    "# diffraction peaks\n",
    "# updated the scaler:\n",
    "structure_scaler.partial_fit(new_data_good[features])\n",
    "# update the model\n",
    "structure_model.partial_fit(structure_scaler.transform(new_data_good[features]), new_data_good['structure'], classes=[True, False])\n",
    "\n",
    "scores = structure_model.score(structure_scaler.transform(new_data_good[features]), new_data_good['structure'])\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save updated scalers and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_version = list(map(int,sklearn.__version__.split('.')))\n",
    "major,minor,patch = current_version\n",
    "\n",
    "scalers = {} \n",
    "models = {}\n",
    "scalers_and_models = {'version':current_version, 'scalers' : scalers, 'models': models}\n",
    "\n",
    "scalers['bad_data'] = bad_data_scaler.__dict__\n",
    "models['bad_data'] = bad_data_model.__dict__\n",
    "\n",
    "scalers['form_factor_scattering'] = form_scaler.__dict__\n",
    "models['form_factor_scattering'] = form_model.__dict__\n",
    "\n",
    "scalers['precursor_scattering'] = precursor_scaler.__dict__\n",
    "models['precursor_scattering'] = precursor_model.__dict__\n",
    "\n",
    "scalers['diffraction_peaks'] = structure_scaler.__dict__\n",
    "models['diffraction_peaks'] = structure_model.__dict__\n",
    "\n",
    "with open('scalers_and_models.yml', 'w') as yaml_file:\n",
    "    yaml.dump(scalers_and_models, yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': {'bad_data': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[  2.23294798, -11.70177602,   5.25285292,   0.10739561,\n",
       "             0.23208343]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([-12.76920557]),\n",
       "   'l1_ratio': 0.95,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a14835b88>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 1,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'elasticnet',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 10643.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'diffraction_peaks': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[-9.50249827,  1.46692761,  9.85193415, -0.46371014, -0.06324698]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([-3.24304453]),\n",
       "   'l1_ratio': 0.15,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a14835fa8>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 1,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'l1',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8948.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'form_factor_scattering': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[ -2.1567205 ,  27.22611227,  -2.1866569 ,  -0.57177285,\n",
       "            -0.89875947]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([ 15.62775471]),\n",
       "   'l1_ratio': 0.15,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a379da888>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 1,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'none',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8950.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'precursor_scattering': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.01,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[-0.0229643 , -2.60494165,  1.53013037,  0.07776887,  0.74806226]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([ 0.05934242]),\n",
       "   'l1_ratio': 0.95,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a379da948>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 1,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'l1',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8477.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False}},\n",
       " 'scalers': {'bad_data': {'copy': True,\n",
       "   'mean_': array([  0.07271051,  18.10476166,   1.44068299,   5.02940395,   3.26348357]),\n",
       "   'n_samples_seen_': 2696,\n",
       "   'scale_': array([  0.0918374 ,  19.56652396,   0.70059955,   2.93338112,   1.05901478]),\n",
       "   'var_': array([  8.43410856e-03,   3.82848860e+02,   4.90839734e-01,\n",
       "            8.60472478e+00,   1.12151230e+00]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'diffraction_peaks': {'copy': True,\n",
       "   'mean_': array([  0.05753409,  19.08948207,   1.43921578,   4.77794689,   3.28164064]),\n",
       "   'n_samples_seen_': 2543,\n",
       "   'scale_': array([  0.03817834,  19.71512019,   0.69389311,   2.26174384,   0.92198068]),\n",
       "   'var_': array([  1.45758558e-03,   3.88685964e+02,   4.81487643e-01,\n",
       "            5.11548521e+00,   8.50048383e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'form_factor_scattering': {'copy': True,\n",
       "   'mean_': array([  0.05779848,  19.07543634,   1.43896835,   4.77565267,   3.28285172]),\n",
       "   'n_samples_seen_': 2545,\n",
       "   'scale_': array([  0.03960263,  19.71373527,   0.69368214,   2.26233511,   0.92263688]),\n",
       "   'var_': array([  1.56836792e-03,   3.88631358e+02,   4.81194906e-01,\n",
       "            5.11816013e+00,   8.51258818e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'precursor_scattering': {'copy': True,\n",
       "   'mean_': array([  0.05753409,  19.08948207,   1.43921578,   4.77794689,   3.28164064]),\n",
       "   'n_samples_seen_': 2543,\n",
       "   'scale_': array([  0.03817834,  19.71512019,   0.69389311,   2.26174384,   0.92198068]),\n",
       "   'var_': array([  1.45758558e-03,   3.88685964e+02,   4.81487643e-01,\n",
       "            5.11548521e+00,   8.50048383e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True}},\n",
       " 'version': [0, 19, 0]}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('scalers_and_models.yml') as info:\n",
    "      s_and_m = yaml.load(info)\n",
    "s_and_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
