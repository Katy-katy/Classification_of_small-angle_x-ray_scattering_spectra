{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data from Citrination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from citrination_client import CitrinationClient\n",
    "from citrination_client import PifQuery\n",
    "from pypif.pif import dumps\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = CitrinationClient(site='my_site',api_key='my_key' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_datasets = [1,15,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return list of all ids and \n",
    "# a dictionary where keys are ids of samples, values are the pandas dataframes\n",
    "# with two columns - 'q' and 'I'\n",
    "def get_data_from_Citrination(client, dataset_id_list):\n",
    "    all_samples_names = [] # list of all id only - we can use it for random access\n",
    "    data = {} # dict where keys are ids of samples\n",
    "    for dataset in dataset_id_list:\n",
    "        query_dataset = PifQuery(include_datasets=[dataset])\n",
    "        query_result = client.search(query_dataset)\n",
    "        pifs = [x.system for x in query_result.hits]\n",
    "        for line in pifs:\n",
    "            my_str = dumps(line)\n",
    "            obj = json.loads(my_str) # to transform the string to dictionary\n",
    "            for pr in obj['properties']:\n",
    "                if pr['name'] == 'SAXS intensity':\n",
    "                    q_list_of_dic = pr['conditions'][0]['scalars'] # q\n",
    "                    q_list = []\n",
    "                    for i in q_list_of_dic:\n",
    "                        for k, v in i.items():\n",
    "                            q_list.append(v)\n",
    "                    I_list_of_dic = pr['scalars']# I\n",
    "                    I_list = []\n",
    "                    for i in I_list_of_dic:\n",
    "                        for k, v in i.items():\n",
    "                            I_list.append(v)\n",
    "                    if (len(q_list) != 560 or len(I_list) != 560):\n",
    "                        continue\n",
    "                    sample_id = \"set_\" + str(dataset) + \"_\" + obj['uid']\n",
    "                    all_samples_names.append(sample_id)\n",
    "                    df = pd.DataFrame.from_dict({'q': q_list, 'I' : I_list})\n",
    "                    df = df.astype(float)\n",
    "                    data[sample_id] = df\n",
    "    return all_samples_names, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Features: 'name', 'q_Imax', 'Imax_over_Imean','Imax_over_Imean_local', 'fluctuation_strength', 'low_q_ratio',\n",
    "                 'high_q_ratio', 'Imax_over_Ilowq','Imax_over_Ihighq', 'Ilowq_over_Ihighq', 'b_s_1', 'b_s_2','b_s_3',\n",
    "                 'b_s_4', 'b_s_5', 'b_s_6', 'b_s_7', 'b_s_8', 'b_s_9', 'b_s_10','b_s_11', 'b_s_12','b_s_13',\n",
    "                 'b_s_14', 'b_s_15', 'b_s_16', 'b_s_17', 'b_s_18', 'b_s_19', 'b_s_20'\n",
    "'''\n",
    "def extract_features(df, name):\n",
    "    features = []\n",
    "    q = np.array(df['q'])\n",
    "    I = np.array(df['I'])\n",
    "    \n",
    "    idxmax = np.argmax(I)\n",
    "    Imax = I[idxmax]\n",
    "    q_Imax = q[idxmax]\n",
    "    \n",
    "    idxmin = np.argmin(I)\n",
    "    Imin = I[idxmin]\n",
    "    Irange = Imax - Imin\n",
    "    Imean = np.mean(I)\n",
    "    Imax_over_Imean = float(Imax)/float(Imean)\n",
    "    \n",
    "    idx_around_max = ((q > 0.9*q_Imax) & (q < 1.1*q_Imax))\n",
    "    Imean_around_max = np.mean(I[idx_around_max])\n",
    "    Imax_over_Imean_local = Imax / Imean_around_max\n",
    "    \n",
    "    ### fluctuation analysis\n",
    "    # array of the difference between neighboring points:\n",
    "    nn_diff = I[1:]-I[:-1]\n",
    "    # keep indices where the sign of this difference changes.\n",
    "    # also keep first index\n",
    "    nn_diff_prod = nn_diff[1:]*nn_diff[:-1]\n",
    "    idx_keep = np.hstack((np.array([True]),nn_diff_prod<0))\n",
    "    fluc = np.sum(np.abs(nn_diff[idx_keep]))\n",
    "    fluctuation_strength = fluc/Imean\n",
    "    \n",
    "    I_sum = np.sum(I)\n",
    "    low_q_ratio = np.sum(I[(q<0.4)])/I_sum\n",
    "    high_q_ratio = np.sum(I[(q>=0.4)])/I_sum\n",
    "    \n",
    "    ### curve shape analysis\n",
    "    lowq_idx = q<0.1\n",
    "    highq_idx = q>0.4\n",
    "    lowq = q[lowq_idx]\n",
    "    highq = q[highq_idx]\n",
    "    I_lowq = I[lowq_idx]\n",
    "    I_highq = I[highq_idx]\n",
    "    I_lowq_mean = np.mean(I_lowq)\n",
    "    I_highq_mean = np.mean(I_highq)\n",
    "    Imax_over_Ilowq = float(Imax)/I_lowq_mean\n",
    "    Ilowq_over_Ihighq = I_lowq_mean/I_highq_mean\n",
    "    Imax_over_Ihighq = float(Imax)/I_highq_mean\n",
    "    \n",
    "    bin_strengths = np.zeros(20)\n",
    "    for i in range(20):\n",
    "            qmini, qmaxi = i*0.05, (i+1)*0.05\n",
    "            idxi = ((q>=qmini) & (q<qmaxi))\n",
    "            if any(idxi):\n",
    "                qi = q[ idxi ]\n",
    "                Ii = I[ idxi ]/Imax # /Imax added\n",
    "                dqi = qi[1:]-qi[:-1]\n",
    "                Ii = (Ii[1:]+Ii[:-1])/2\n",
    "                bin_strengths[i] = np.sum(np.log(Ii) * dqi) / (qi[-1]-qi[0])\n",
    "  \n",
    "\n",
    "    features.append(name)\n",
    "    features.append(q_Imax)\n",
    "    features.append(Imax_over_Imean)\n",
    "    features.append(Imax_over_Imean_local)\n",
    "    features.append(fluctuation_strength)\n",
    "    features.append(low_q_ratio)\n",
    "    features.append(high_q_ratio)\n",
    "    features.append(Imax_over_Ilowq)\n",
    "    features.append(Imax_over_Ihighq)\n",
    "    features.append(Ilowq_over_Ihighq)\n",
    "    \n",
    "    for s in bin_strengths:\n",
    "        features.append(s)\n",
    "                  \n",
    "    return tuple(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data_frame(data, names):\n",
    "    data_set = [] \n",
    "\n",
    "    columns = ['name', 'q_Imax', 'Imax_over_Imean','Imax_over_Imean_local', 'fluctuation_strength', 'low_q_ratio',\n",
    "                 'high_q_ratio', 'Imax_over_Ilowq','Imax_over_Ihighq', 'Ilowq_over_Ihighq', 'b_s_1', 'b_s_2','b_s_3',\n",
    "                 'b_s_4', 'b_s_5', 'b_s_6', 'b_s_7', 'b_s_8', 'b_s_9', 'b_s_10','b_s_11', 'b_s_12','b_s_13',\n",
    "                 'b_s_14', 'b_s_15', 'b_s_16', 'b_s_17', 'b_s_18', 'b_s_19', 'b_s_20' ]\n",
    "    for f in names:\n",
    "        df = data[f]\n",
    "        data_set.append(extract_features(df, f))\n",
    "    data_frame = pd.DataFrame.from_records(data_set, columns=columns)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Features: whole q array\n",
    "'''\n",
    "def extract_features2(df, name):\n",
    "    features = []\n",
    "    i = np.array(df['I'])\n",
    "    features.append(name)\n",
    "    for s in i:\n",
    "        features.append(s)           \n",
    "    return tuple(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using whole q array as features\n",
    "def create_data_frame2(data, names):\n",
    "    data_set = [] \n",
    "    columns = list(range(0, 560))\n",
    "    columns = list(map(str, columns))\n",
    "    columns.insert( 0, 'name')\n",
    "\n",
    "    for f in names:\n",
    "        df = data[f]\n",
    "        data_set.append(extract_features2(df, f))\n",
    "    data_frame = pd.DataFrame.from_records(data_set, columns=columns)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_data_and_create_df(client, dataset_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def create_and_save_model(client, dataset_id_list):\n",
    "    names, data = get_data_from_Citrination(client, dataset_id_list)\n",
    "    df = create_data_frame(data, names)\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(df[features])\n",
    "    # put my best unsupervised model here\n",
    "    # for example:\n",
    "    # clusterer = MiniBatchKMeans(n_clusters=n_clusters, random_state=10)\n",
    "    # clusterer.fit(scaler.transform(df[features]))\n",
    "    #model.to_pickle('unsupervised_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# it is a temporary function for testing\n",
    "def get_data_and_create_df(client, dataset_id_list):\n",
    "    names, data = get_data_from_Citrination(client, dataset_id_list)\n",
    "    df = create_data_frame(data, names)\n",
    "    return df\n",
    "\n",
    "def get_data_and_create_df2(client, dataset_id_list):\n",
    "    names, data = get_data_from_Citrination(client, dataset_id_list)\n",
    "    df = create_data_frame2(data, names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame = get_data_and_create_df(client, list_of_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>550</th>\n",
       "      <th>551</th>\n",
       "      <th>552</th>\n",
       "      <th>553</th>\n",
       "      <th>554</th>\n",
       "      <th>555</th>\n",
       "      <th>556</th>\n",
       "      <th>557</th>\n",
       "      <th>558</th>\n",
       "      <th>559</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set_1_R1_1479582658</td>\n",
       "      <td>1.143534</td>\n",
       "      <td>0.497115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.473436</td>\n",
       "      <td>0.487803</td>\n",
       "      <td>0.906999</td>\n",
       "      <td>1.823430</td>\n",
       "      <td>1.289826</td>\n",
       "      <td>1.694177</td>\n",
       "      <td>...</td>\n",
       "      <td>2.251870</td>\n",
       "      <td>2.112009</td>\n",
       "      <td>2.084345</td>\n",
       "      <td>2.232733</td>\n",
       "      <td>2.299173</td>\n",
       "      <td>2.220341</td>\n",
       "      <td>2.055935</td>\n",
       "      <td>2.028783</td>\n",
       "      <td>2.046827</td>\n",
       "      <td>2.168071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>set_1_R1_1479582669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.135393</td>\n",
       "      <td>1.251626</td>\n",
       "      <td>0.702255</td>\n",
       "      <td>0.592320</td>\n",
       "      <td>0.419255</td>\n",
       "      <td>1.134044</td>\n",
       "      <td>1.444593</td>\n",
       "      <td>1.232273</td>\n",
       "      <td>...</td>\n",
       "      <td>1.831821</td>\n",
       "      <td>2.005809</td>\n",
       "      <td>1.915149</td>\n",
       "      <td>1.888664</td>\n",
       "      <td>1.899058</td>\n",
       "      <td>1.803673</td>\n",
       "      <td>1.824841</td>\n",
       "      <td>1.802742</td>\n",
       "      <td>1.857838</td>\n",
       "      <td>1.863579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>set_1_R1_1479582681</td>\n",
       "      <td>0.021854</td>\n",
       "      <td>0.157678</td>\n",
       "      <td>0.295437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678777</td>\n",
       "      <td>0.898697</td>\n",
       "      <td>0.880770</td>\n",
       "      <td>1.121462</td>\n",
       "      <td>1.715802</td>\n",
       "      <td>...</td>\n",
       "      <td>1.793492</td>\n",
       "      <td>1.713437</td>\n",
       "      <td>1.781256</td>\n",
       "      <td>1.888325</td>\n",
       "      <td>1.836691</td>\n",
       "      <td>1.850607</td>\n",
       "      <td>1.762937</td>\n",
       "      <td>1.877357</td>\n",
       "      <td>1.942171</td>\n",
       "      <td>1.954817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name         0         1         2         3         4  \\\n",
       "0  set_1_R1_1479582658  1.143534  0.497115  0.000000  0.473436  0.487803   \n",
       "1  set_1_R1_1479582669  0.000000  1.135393  1.251626  0.702255  0.592320   \n",
       "2  set_1_R1_1479582681  0.021854  0.157678  0.295437  0.000000  0.678777   \n",
       "\n",
       "          5         6         7         8    ...          550       551  \\\n",
       "0  0.906999  1.823430  1.289826  1.694177    ...     2.251870  2.112009   \n",
       "1  0.419255  1.134044  1.444593  1.232273    ...     1.831821  2.005809   \n",
       "2  0.898697  0.880770  1.121462  1.715802    ...     1.793492  1.713437   \n",
       "\n",
       "        552       553       554       555       556       557       558  \\\n",
       "0  2.084345  2.232733  2.299173  2.220341  2.055935  2.028783  2.046827   \n",
       "1  1.915149  1.888664  1.899058  1.803673  1.824841  1.802742  1.857838   \n",
       "2  1.781256  1.888325  1.836691  1.850607  1.762937  1.877357  1.942171   \n",
       "\n",
       "        559  \n",
       "0  2.168071  \n",
       "1  1.863579  \n",
       "2  1.954817  \n",
       "\n",
       "[3 rows x 561 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with q as features\n",
    "data_frame2 = get_data_and_create_df2(client, list_of_datasets)\n",
    "data_frame2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2170, 561)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the dataframe with analytical features and bins\n",
    "data_frame.to_pickle('df_for_clustering.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the dataframe with whole q array as features\n",
    "data_frame2.to_pickle('df_for_clustering2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
