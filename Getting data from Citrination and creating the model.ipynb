{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data from Citrination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from citrination_client import CitrinationClient\n",
    "from citrination_client import PifQuery\n",
    "from pypif.pif import dumps\n",
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import yaml\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#client = CitrinationClient(site='my_site',api_key='my_key' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_datasets = [1,15,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['q_Imax', 'Imax_over_Imean', 'Imax_sharpness','logI_fluctuation', 'logI_max_over_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return dataframe with features and labels \n",
    "def get_data_from_Citrination(client, dataset_id_list):\n",
    "    df = pd.DataFrame(columns= [[ 'q_Imax', 'Imax_over_Imean', 'Imax_sharpness','logI_fluctuation', 'logI_max_over_std', 'bad_data', 'form', 'precursor', 'structure']])\n",
    "    for dataset in dataset_id_list:\n",
    "        query_dataset = PifQuery(include_datasets=[dataset])\n",
    "        query_result = client.search(query_dataset)\n",
    "        pifs = [x.system for x in query_result.hits]\n",
    "        for line in pifs: # every line of pifs is one sample; we need to extract labels and features from it\n",
    "            try:\n",
    "                my_str = dumps(line)\n",
    "                obj = json.loads(my_str) # to transform the string to dictionary\n",
    "                \n",
    "                # default values for labels\n",
    "                bad_data = False\n",
    "                form = False\n",
    "                precursor = False\n",
    "                structure = False\n",
    "                    \n",
    "                for pr in obj['properties']:\n",
    "\n",
    "                    # extract features                    \n",
    "                    if pr['name'] == 'q_Imax':\n",
    "                        q_Imax = np.float32(pr['scalars'][0]['value'])\n",
    "                    if pr['name'] == 'Imax_over_Imean':\n",
    "                        Imax_over_Imean = np.float32(pr['scalars'][0]['value'])\n",
    "                    if pr['name'] == 'Imax_sharpness':\n",
    "                        Imax_sharpness = np.float32(pr['scalars'][0]['value'])\n",
    "                    if pr['name'] == 'logI_fluctuation':\n",
    "                        logI_fluctuation = np.float32(pr['scalars'][0]['value'])\n",
    "                    if pr['name'] == 'logI_max_over_std':\n",
    "                        logI_max_over_std = np.float32(pr['scalars'][0]['value'])\n",
    "\n",
    "                    # extract labels\n",
    "                    if pr['name'] == 'bad_data':\n",
    "                        bad_data = True\n",
    "                        continue\n",
    "                    if pr['name'] == 'form_factor_scattering':\n",
    "                        form = True\n",
    "                    if pr['name'] == 'diffraction_peaks':\n",
    "                        structure = True\n",
    "                    if pr['name'] == 'precursor scattering':\n",
    "                        precursor = True\n",
    "\n",
    "                df.loc[df.shape[0]] = [q_Imax, Imax_over_Imean, Imax_sharpness, logI_fluctuation, \n",
    "                                           logI_max_over_std, bad_data, form, precursor, structure]\n",
    "            except:\n",
    "                # May be in PAWS we need to put a custom exeption here\n",
    "                my_str = dumps(line)\n",
    "                obj = json.loads(my_str) # to transform the string to dictionary\n",
    "                print(obj)\n",
    "                continue\n",
    "                                 \n",
    "    return df.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = get_data_from_Citrination(client, list_of_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_Imax</th>\n",
       "      <th>Imax_over_Imean</th>\n",
       "      <th>Imax_sharpness</th>\n",
       "      <th>logI_fluctuation</th>\n",
       "      <th>logI_max_over_std</th>\n",
       "      <th>bad_data</th>\n",
       "      <th>form</th>\n",
       "      <th>precursor</th>\n",
       "      <th>structure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.488538</td>\n",
       "      <td>1.312717</td>\n",
       "      <td>1.271242</td>\n",
       "      <td>7.916098</td>\n",
       "      <td>6.268310</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.275225</td>\n",
       "      <td>1.234932</td>\n",
       "      <td>1.132456</td>\n",
       "      <td>9.904497</td>\n",
       "      <td>5.549794</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.357429</td>\n",
       "      <td>1.275898</td>\n",
       "      <td>1.166689</td>\n",
       "      <td>5.827428</td>\n",
       "      <td>3.660412</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.336618</td>\n",
       "      <td>1.240092</td>\n",
       "      <td>1.143083</td>\n",
       "      <td>7.461594</td>\n",
       "      <td>4.006636</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.227360</td>\n",
       "      <td>1.254006</td>\n",
       "      <td>1.229550</td>\n",
       "      <td>6.997641</td>\n",
       "      <td>5.272323</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     q_Imax  Imax_over_Imean  Imax_sharpness  logI_fluctuation  \\\n",
       "0  0.488538         1.312717        1.271242          7.916098   \n",
       "1  0.275225         1.234932        1.132456          9.904497   \n",
       "2  0.357429         1.275898        1.166689          5.827428   \n",
       "3  0.336618         1.240092        1.143083          7.461594   \n",
       "4  0.227360         1.254006        1.229550          6.997641   \n",
       "\n",
       "   logI_max_over_std  bad_data   form  precursor  structure  \n",
       "0           6.268310      True  False      False      False  \n",
       "1           5.549794      True  False      False      False  \n",
       "2           3.660412      True  False      False      False  \n",
       "3           4.006636      True  False      False      False  \n",
       "4           5.272323      True  False      False      False  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1750, 9)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_rows = np.random.permutation(d.index)\n",
    "data = d.loc[shuffled_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 19, 0]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to save the version of sklearn to use in PAWS\n",
    "current_version = list(map(int,sklearn.__version__.split('.')))\n",
    "major,minor,patch = current_version\n",
    "current_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am saving version of sklearn with all scalers and models. \n",
    "# Then I will dump them into a yaml file that will be used in PAWS app.\n",
    "scalers = {} \n",
    "models = {}\n",
    "scalers_and_models = {'version':current_version, 'scalers' : scalers, 'models': models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bad Data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to train the model on all avalible data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data[features])\n",
    "log = linear_model.SGDClassifier(alpha= 0.001,loss= 'log', l1_ratio= 0.95, penalty= 'elasticnet')\n",
    "log.fit(scaler.transform(data[features]), data['bad_data'])\n",
    "\n",
    "# save the scaler and model\n",
    "scalers['bad_data'] = scaler.__dict__\n",
    "models['bad_data'] = log.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bad data score:  0.976571428571\n"
     ]
    }
   ],
   "source": [
    "score = log.score(scaler.transform(data[features]), data['bad_data']) # here I test on the same data just to be sure the model works\n",
    "print(\"bad data score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we need only \"good\" data\n",
    "data_good = data[data['bad_data']==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form Scattering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to train the model on all avalible data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data_good[features])\n",
    "log = linear_model.SGDClassifier(alpha= 0.001,loss= 'log', penalty= 'none')\n",
    "log.fit(scaler.transform(data_good[features]), data_good['form'])\n",
    "\n",
    "# save the scaler and model\n",
    "scalers['form_factor_scattering'] = scaler.__dict__\n",
    "models['form_factor_scattering'] = log.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "form score:  0.987428571429\n"
     ]
    }
   ],
   "source": [
    "score = log.score(scaler.transform(data[features]), data['form']) # here I test on the same data just to be sure the model works\n",
    "print(\"form score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precursor Scattering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to train the model on all avalible data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data_good[features])\n",
    "log = linear_model.SGDClassifier(alpha= 0.01,loss= 'log', l1_ratio= 0.95, penalty= 'l1')\n",
    "log.fit(scaler.transform(data_good[features]), data_good['precursor'])\n",
    "\n",
    "# save the scaler and model\n",
    "scalers['precursor_scattering'] = scaler.__dict__\n",
    "models['precursor_scattering'] = log.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precursor score:  0.748571428571\n"
     ]
    }
   ],
   "source": [
    "score = log.score(scaler.transform(data[features]), data['precursor']) # here I test on the same data just to be sure the model works\n",
    "print(\"precursor score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffraction Peaks model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to train the model on all avalible data \n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data_good[features])\n",
    "log = linear_model.SGDClassifier(alpha= 0.001,loss= 'log', penalty= 'l1')\n",
    "log.fit(scaler.transform(data_good[features]), data_good['structure'])\n",
    "\n",
    "# save the scaler and model\n",
    "scalers['diffraction_peaks'] = scaler.__dict__\n",
    "models['diffraction_peaks'] = log.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "structure score:  0.954857142857\n"
     ]
    }
   ],
   "source": [
    "score = log.score(scaler.transform(data[features]), data['structure']) # here I test on the same data just to be sure the model works\n",
    "print(\"structure score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('scalers_and_models.yml', 'w') as yaml_file:\n",
    "    yaml.dump(scalers_and_models, yaml_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('scalers_and_models.yml') as info:\n",
    "      s_and_m = yaml.load(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kate/Desktop/SLAC/regression_models'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': {'bad_data': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[ 1.7054912 , -7.60084268,  3.65823375,  0.90331796,  0.        ]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([-8.96693147]),\n",
       "   'l1_ratio': 0.95,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a31cff600>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 5,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'elasticnet',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8751.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'diffraction_peaks': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[ -2.68868881,  13.33492716,  12.78880753,   0.07471522,\n",
       "            -2.87214897]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([ 5.58809546]),\n",
       "   'l1_ratio': 0.15,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a31cff708>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 5,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'l1',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8006.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'form_factor_scattering': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.001,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[ -1.87160505,  24.25515144,  -3.4100058 ,   0.31376229,  -1.6082806 ]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([ 17.04126727]),\n",
       "   'l1_ratio': 0.15,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a31cff870>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 5,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'none',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8006.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False},\n",
       "  'precursor_scattering': {'C': 1.0,\n",
       "   '_expanded_class_weight': array([ 1.,  1.]),\n",
       "   'alpha': 0.01,\n",
       "   'average': False,\n",
       "   'class_weight': None,\n",
       "   'classes_': array([False,  True], dtype=bool),\n",
       "   'coef_': array([[ 0.        , -2.47932879,  1.36086474, -0.21043993,  0.81661934]]),\n",
       "   'epsilon': 0.1,\n",
       "   'eta0': 0.0,\n",
       "   'fit_intercept': True,\n",
       "   'intercept_': array([-0.49533451]),\n",
       "   'l1_ratio': 0.95,\n",
       "   'learning_rate': 'optimal',\n",
       "   'loss': 'log',\n",
       "   'loss_function_': <sklearn.linear_model.sgd_fast.Log at 0x1a31cff930>,\n",
       "   'max_iter': 5,\n",
       "   'n_iter_': 5,\n",
       "   'n_jobs': 1,\n",
       "   'penalty': 'l1',\n",
       "   'power_t': 0.5,\n",
       "   'random_state': None,\n",
       "   'shuffle': True,\n",
       "   't_': 8006.0,\n",
       "   'tol': None,\n",
       "   'verbose': 0,\n",
       "   'warm_start': False}},\n",
       " 'scalers': {'bad_data': {'copy': True,\n",
       "   'mean_': array([  0.08458954,  20.3550401 ,   1.47136581,   5.36497042,   3.28268276]),\n",
       "   'n_samples_seen_': 1750,\n",
       "   'scale_': array([  0.10980206,  19.56918947,   0.70150315,   3.13884604,   1.16960072]),\n",
       "   'var_': array([  1.20564923e-02,   3.82953177e+02,   4.92106665e-01,\n",
       "            9.85235446e+00,   1.36796585e+00]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'diffraction_peaks': {'copy': True,\n",
       "   'mean_': array([  0.06239179,  22.08638401,   1.47110058,   4.98886844,   3.31720565]),\n",
       "   'n_samples_seen_': 1601,\n",
       "   'scale_': array([  0.04512096,  19.57581255,   0.69030832,   2.15678619,   0.98034173]),\n",
       "   'var_': array([  2.03590064e-03,   3.83212437e+02,   4.76525573e-01,\n",
       "            4.65172667e+00,   9.61069902e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'form_factor_scattering': {'copy': True,\n",
       "   'mean_': array([  0.06239179,  22.08638401,   1.47110058,   4.98886844,   3.31720565]),\n",
       "   'n_samples_seen_': 1601,\n",
       "   'scale_': array([  0.04512096,  19.57581255,   0.69030832,   2.15678619,   0.98034173]),\n",
       "   'var_': array([  2.03590064e-03,   3.83212437e+02,   4.76525573e-01,\n",
       "            4.65172667e+00,   9.61069902e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True},\n",
       "  'precursor_scattering': {'copy': True,\n",
       "   'mean_': array([  0.06239179,  22.08638401,   1.47110058,   4.98886844,   3.31720565]),\n",
       "   'n_samples_seen_': 1601,\n",
       "   'scale_': array([  0.04512096,  19.57581255,   0.69030832,   2.15678619,   0.98034173]),\n",
       "   'var_': array([  2.03590064e-03,   3.83212437e+02,   4.76525573e-01,\n",
       "            4.65172667e+00,   9.61069902e-01]),\n",
       "   'with_mean': True,\n",
       "   'with_std': True}},\n",
       " 'version': [0, 19, 0]}"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_and_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
